From f969d8a7c0de0943848366fd73861acf551f8b3b Mon Sep 17 00:00:00 2001
From: Aaron <kljsandjb@me.com>
Date: Thu, 16 Jul 2020 12:55:29 +0000
Subject: [PATCH] try with fine-grained locks..

adding lock for:
1. page allocator
2. scheduler
3. console
4. ipc state

haven't checked IPC lock, but it looks good now,
run once and got 80/80, will re-run several times
---
 inc/env.h        |  1 +
 kern/env.c       | 20 ++++++++++++++++----
 kern/init.c      |  5 ++---
 kern/monitor.c   |  6 ------
 kern/pmap.c      |  6 ++++++
 kern/sched.c     |  4 ++--
 kern/spinlock.c  | 34 +++++++++++++++++++++++++++++++---
 kern/spinlock.h  | 50 +++++++++++++++++++++++++++++++-------------------
 kern/syscall.c   |  3 +++
 kern/trap.c      | 11 ++++++++---
 kern/trapentry.S | 30 +++++++++++++++---------------
 11 files changed, 115 insertions(+), 55 deletions(-)

diff --git a/inc/env.h b/inc/env.h
index b04f1a3..13df7de 100644
--- a/inc/env.h
+++ b/inc/env.h
@@ -32,6 +32,7 @@ typedef int32_t envid_t;
 // Values of env_status in struct Env
 enum {
 	ENV_FREE = 0,
+	ENV_EMBRYO,
 	ENV_DYING,
 	ENV_RUNNABLE,
 	ENV_RUNNING,
diff --git a/kern/env.c b/kern/env.c
index e1019da..103c241 100644
--- a/kern/env.c
+++ b/kern/env.c
@@ -220,12 +220,23 @@ env_alloc(struct Env **newenv_store, envid_t parent_id)
 	int r;
 	struct Env *e;
 
+	LOCK(env);
 	if (!(e = env_free_list))
+	{
+		UNLOCK(env);
 		return -E_NO_FREE_ENV;
+	}
 
 	// Allocate and set up the page directory for this environment.
 	if ((r = env_setup_vm(e)) < 0)
+	{
+		UNLOCK(env);
 		return r;
+	}
+
+	// commit the allocation
+	env_free_list = e->env_link;
+	UNLOCK(env);
 
 	// Generate an env_id for this environment.
 	generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
@@ -236,7 +247,7 @@ env_alloc(struct Env **newenv_store, envid_t parent_id)
 	// Set the basic status variables.
 	e->env_parent_id = parent_id;
 	e->env_type = ENV_TYPE_USER;
-	e->env_status = ENV_RUNNABLE;
+	e->env_status = ENV_EMBRYO;
 	e->env_runs = 0;
 
 	// Clear out all the saved register state,
@@ -270,8 +281,6 @@ env_alloc(struct Env **newenv_store, envid_t parent_id)
 	// Also clear the IPC receiving flag.
 	e->env_ipc_recving = 0;
 
-	// commit the allocation
-	env_free_list = e->env_link;
 	*newenv_store = e;
 
 	cprintf("[%08x] new env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
@@ -417,6 +426,7 @@ env_create(uint8_t *binary, enum EnvType type)
 		panic("env_alloc");
 	load_icode(new_env, binary);
 	new_env->env_type = type;
+	new_env->env_status = ENV_RUNNABLE;
 }
 
 //
@@ -468,8 +478,10 @@ env_free(struct Env *e)
 
 	// return the environment to the free list
 	e->env_status = ENV_FREE;
+	LOCK(env);
 	e->env_link = env_free_list;
 	env_free_list = e;
+	UNLOCK(env);
 }
 
 //
@@ -557,7 +569,7 @@ env_run(struct Env *e)
 	curenv->env_runs ++;
 
 	lcr3(PADDR(curenv->env_pgdir));
-	unlock_kernel();
+	UNLOCK(sched);
 	env_pop_tf(&(curenv->env_tf));
 }
 
diff --git a/kern/init.c b/kern/init.c
index 0a0faaa..b551aaf 100644
--- a/kern/init.c
+++ b/kern/init.c
@@ -43,7 +43,7 @@ i386_init(void)
 
 	// Acquire the big kernel lock before waking up APs
 	// Your code here:
-	lock_kernel();
+	LOCK(sched);
 
 	// Starting non-boot CPUs
 	boot_aps();
@@ -62,7 +62,7 @@ i386_init(void)
 	ENV_CREATE(user_yield, ENV_TYPE_USER);
 	ENV_CREATE(user_yield, ENV_TYPE_USER);
 #endif // TEST*
-
+	UNLOCK(sched);	// tasks are all ready, now start scheduling
 	// Schedule and run the first user environment!
 	sched_yield();
 }
@@ -117,7 +117,6 @@ mp_main(void)
 	// only one CPU can enter the scheduler at a time!
 	//
 	// Your code here:
-	lock_kernel();
 	sched_yield();
 
 	// Remove this after you finish Exercise 6
diff --git a/kern/monitor.c b/kern/monitor.c
index c46e3fb..ac6a91e 100644
--- a/kern/monitor.c
+++ b/kern/monitor.c
@@ -145,20 +145,14 @@ int mon_debug(int argc, char **argv, struct Trapframe *tf)
 	}
 
 	extern void env_pop_tf(struct Trapframe *tf);
-	extern struct spinlock kernel_lock;
-	void spin_unlock(struct spinlock *lk);
 	if (strncmp("si", argv[1], 10) == 0)
 	{
-		spin_unlock(&kernel_lock);
-		asm volatile("pause");
 		env_pop_tf(tf);
 	}
 	if (strncmp("continue", argv[1], 10) == 0)
 	{
 		// clear TF flag to disable IRQ1
 		tf->tf_eflags &= ~0x100;
-		spin_unlock(&kernel_lock);
-		asm volatile("pause");
 		env_pop_tf(tf);
 	}
 
diff --git a/kern/pmap.c b/kern/pmap.c
index c2e22a7..bb1ad5c 100644
--- a/kern/pmap.c
+++ b/kern/pmap.c
@@ -10,6 +10,7 @@
 #include <kern/kclock.h>
 #include <kern/env.h>
 #include <kern/cpu.h>
+#include <kern/spinlock.h>
 
 // These variables are set by i386_detect_memory()
 size_t npages;			// Amount of physical memory (in pages)
@@ -387,14 +388,17 @@ struct PageInfo *
 page_alloc(int alloc_flags)
 {
 	// Fill this function in
+	LOCK(page);
 	if (page_free_list == NULL)
 	{
+		UNLOCK(page);
 		return NULL;
 	}
 
 	struct PageInfo *alloc_page;
 	alloc_page = page_free_list;
 	page_free_list = page_free_list->pp_link;
+	UNLOCK(page);
 	alloc_page->pp_link = NULL;
 
 	if (alloc_flags & ALLOC_ZERO)
@@ -423,8 +427,10 @@ page_free(struct PageInfo *pp)
 	{
 		panic("Page is still in use! Cannot be freed");
 	}
+	LOCK(page);
 	pp->pp_link = page_free_list;
 	page_free_list = pp;
+	UNLOCK(page);
 }
 
 //
diff --git a/kern/sched.c b/kern/sched.c
index 9e464d7..4ac40ae 100644
--- a/kern/sched.c
+++ b/kern/sched.c
@@ -11,7 +11,7 @@ void sched_halt(void);
 void
 sched_yield(void)
 {
-	struct Env *idle;
+	LOCK(sched);
 
 	// Implement simple round-robin scheduling.
 	// https://www.geeksforgeeks.org/program-round-robin-scheduling-set-1/
@@ -82,7 +82,7 @@ sched_halt(void)
 	xchg(&thiscpu->cpu_status, CPU_HALTED);
 
 	// Release the big kernel lock as if we were "leaving" the kernel
-	unlock_kernel();
+	UNLOCK(sched);
 
 	// Reset stack pointer, enable interrupts and then halt.
 	asm volatile (
diff --git a/kern/spinlock.c b/kern/spinlock.c
index bf4d2d2..49d36e5 100644
--- a/kern/spinlock.c
+++ b/kern/spinlock.c
@@ -9,10 +9,38 @@
 #include <kern/spinlock.h>
 #include <kern/kdebug.h>
 
-// The big kernel lock
-struct spinlock kernel_lock = {
+// The big kernel lock (Now we drop it!)
+// struct spinlock kernel_lock = {
+// #ifdef DEBUG_SPINLOCK
+// 	.name = "kernel_lock"
+// #endif
+// };
+
+// memory allocation lock (alloc, free)
+struct spinlock page_lock = {
+#ifdef DEBUG_SPINLOCK
+	.name = "page_lock"
+#endif
+};
+
+// scheduler lock
+struct spinlock sched_lock = {
+#ifdef DEBUG_SPINLOCK
+	.name = "sched_lock"
+#endif
+};
+
+// scheduler lock
+struct spinlock cons_lock = {
+#ifdef DEBUG_SPINLOCK
+	.name = "cons_lock"
+#endif
+};
+
+// env list lock
+struct spinlock env_lock = {
 #ifdef DEBUG_SPINLOCK
-	.name = "kernel_lock"
+	.name = "env_lock"
 #endif
 };
 
diff --git a/kern/spinlock.h b/kern/spinlock.h
index 52d20b4..37a77e5 100644
--- a/kern/spinlock.h
+++ b/kern/spinlock.h
@@ -25,24 +25,36 @@ void spin_unlock(struct spinlock *lk);
 
 #define spin_initlock(lock)   __spin_initlock(lock, #lock)
 
-extern struct spinlock kernel_lock;
-
-static inline void
-lock_kernel(void)
-{
-	spin_lock(&kernel_lock);
-}
-
-static inline void
-unlock_kernel(void)
-{
-	spin_unlock(&kernel_lock);
-
-	// Normally we wouldn't need to do this, but QEMU only runs
-	// one CPU at a time and has a long time-slice.  Without the
-	// pause, this CPU is likely to reacquire the lock before
-	// another CPU has even been given a chance to acquire it.
-	asm volatile("pause");
-}
+// extern struct spinlock kernel_lock;
+extern struct spinlock page_lock;
+extern struct spinlock sched_lock;
+extern struct spinlock cons_lock;
+extern struct spinlock env_lock;
+
+#define CAT(x, y) x ## y
+#define LOCK(type) spin_lock(&CAT(type, _lock))
+#define UNLOCK(type) \
+	do {			\
+		spin_unlock(&CAT(type, _lock)); \
+		asm volatile("pause");		\
+	} while (0)
+
+// static inline void
+// lock_kernel(void)
+// {
+// 	spin_lock(&kernel_lock);
+// }
+
+// static inline void
+// unlock_kernel(void)
+// {
+// 	spin_unlock(&kernel_lock);
+
+// 	// Normally we wouldn't need to do this, but QEMU only runs
+// 	// one CPU at a time and has a long time-slice.  Without the
+// 	// pause, this CPU is likely to reacquire the lock before
+// 	// another CPU has even been given a chance to acquire it.
+// 	asm volatile("pause");
+// }
 
 #endif
diff --git a/kern/syscall.c b/kern/syscall.c
index f19a51f..f61dce6 100644
--- a/kern/syscall.c
+++ b/kern/syscall.c
@@ -11,6 +11,7 @@
 #include <kern/syscall.h>
 #include <kern/console.h>
 #include <kern/sched.h>
+#include <kern/spinlock.h>
 
 // Print a string to the system console.
 // The string is exactly 'len' characters long.
@@ -25,7 +26,9 @@ sys_cputs(const char *s, size_t len)
 	user_mem_assert(curenv, s, len, PTE_U);
 
 	// Print the string supplied by the user.
+	LOCK(cons);
 	cprintf("%.*s", len, s);
+	UNLOCK(cons);
 }
 
 // Read a character from the system console without blocking.
diff --git a/kern/trap.c b/kern/trap.c
index 59027a8..4a78b59 100644
--- a/kern/trap.c
+++ b/kern/trap.c
@@ -275,8 +275,9 @@ trap(struct Trapframe *tf)
 
 	// Re-acqurie the big kernel lock if we were halted in
 	// sched_yield()
-	if (xchg(&thiscpu->cpu_status, CPU_STARTED) == CPU_HALTED)
-		lock_kernel();
+	if (thiscpu->cpu_status == CPU_HALTED)
+		xchg(&thiscpu->cpu_status, CPU_STARTED);
+		// LOCK(sched);
 	// Check that interrupts are disabled.  If this assertion
 	// fails, DO NOT be tempted to fix it by inserting a "cli" in
 	// the interrupt path.
@@ -287,7 +288,7 @@ trap(struct Trapframe *tf)
 		// Acquire the big kernel lock before doing any
 		// serious kernel work.
 		// LAB 4: Your code here.
-		lock_kernel();
+		// lock_kernel();
 
 		// Question 2: Why do we still need separate kernel stacks for each CPU?
 		// Answer: 
@@ -324,7 +325,10 @@ trap(struct Trapframe *tf)
 	// scheduled, so we should return to the current environment
 	// if doing so makes sense.
 	if (curenv && curenv->env_status == ENV_RUNNING)
+	{
+		LOCK(sched);
 		env_run(curenv);
+	}
 	else
 		sched_yield();
 }
@@ -408,6 +412,7 @@ page_fault_handler(struct Trapframe *tf)
 
 	tf->tf_esp = (uintptr_t)&utf->utf_fault_va;
 	tf->tf_eip = (uintptr_t)curenv->env_pgfault_upcall;
+	LOCK(sched);
 	env_run(curenv);
 end:
 	// Destroy the environment that caused the fault.
diff --git a/kern/trapentry.S b/kern/trapentry.S
index aa6bd00..039cc94 100644
--- a/kern/trapentry.S
+++ b/kern/trapentry.S
@@ -60,15 +60,15 @@ default_handlers:
 # (about popf) The I/O privilege level is altered only when executing at privilege level 0. 
 # The interrupt flag is altered only when executing at a level at least as privileged as the I/O privilege level.
 sysenter_handler:
-pushl %ecx
-pushl %edx
-pushl %eax
-pushl $kernel_lock
-call spin_lock
-addl $4, %esp
-popl %eax
-popl %edx
-popl %ecx
+# pushl %ecx
+# pushl %edx
+# pushl %eax
+# pushl $kernel_lock
+# call spin_lock
+# addl $4, %esp
+# popl %eax
+# popl %edx
+# popl %ecx
 
 pushl %edi
 pushl %ebx
@@ -81,12 +81,12 @@ call syscall
 # movl $0, %edx
 # movl $(GD_UT), %eax	/* no need, because of continuity, GD_UT will be found by adding 16(0x10) to GD_KT */
 # wrmsr
-pushl %eax
-pushl $kernel_lock
-call spin_unlock
-pause
-addl $4, %esp
-popl %eax
+# pushl %eax
+# pushl $kernel_lock
+# call spin_unlock
+# pause
+# addl $4, %esp
+# popl %eax
 
 movl %esi, %edx
 movl %ebp, %ecx
-- 
2.11.0

